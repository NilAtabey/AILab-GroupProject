{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch imports\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch import nn\n",
    "import torchmetrics\n",
    "import torchinfo\n",
    "\n",
    "# Utils imports\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GNLDataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dlib\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchnlp.encoders import LabelEncoder\n",
    "\n",
    "import test\n",
    "\n",
    "debug_dl = True\n",
    "\n",
    "class GNLDataLoader(Dataset):\n",
    "    \"\"\"Creates a dataloader for the Lipsync Project\"\"\"\n",
    "    face_detector = dlib.get_frontal_face_detector()\n",
    "    landmark = dlib.shape_predictor(\"shape_predictor_68_face_landmarks_GTX.dat\")\n",
    "\n",
    "    alphabet = [x for x in \"abcdefghijklmnopqrstuvwxyz0123456789 \"]\n",
    "    encoder = LabelEncoder(alphabet, reserved_labels=['unknown'], unknown_index=0)\n",
    "    CROPMARGIN = 20\n",
    "\n",
    "    def __init__(self, labels_path: str, data_path: str, transform = None, train_test_percent: int = 75, debug: bool = False) -> None:\n",
    "        \"\"\"\n",
    "        Creates a dataset given the path to the labels and the image directory\n",
    "\n",
    "        Parameters:\n",
    "            - `labels_path`: the path to the `csv` file containing the labels;\n",
    "            - `images_dir`: the path to the directory with the images;\n",
    "            - `transform`: states whether a transformation should be applied to the images or not.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.debug: bool = debug\n",
    "\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] The data dir has{' ' if os.path.isdir(data_path) else ' not '}been recognized\")\n",
    "            print(f\"[DEBUG] The label dir has{' ' if os.path.isdir(labels_path) else ' not '}been recognized\")\n",
    "\n",
    "        self.data_path, self.labels_path = data_path, labels_path\n",
    "        self.data_dir, self.labels_dir = sorted(os.listdir(data_path)), sorted(os.listdir(labels_path))\n",
    "        self.transform = transform\n",
    "        \n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"\n",
    "        Returns the length of the data/labels folder\n",
    "        \n",
    "        Returns:\n",
    "            - `length` (`int`): the length of the data/labels folder\n",
    "        \"\"\"\n",
    "        return len(self.data_dir)\n",
    "    \n",
    "\n",
    "    def __getitem__(self, index: int, straight: bool = False) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Get the ith item(s) in the dataset\n",
    "        \n",
    "        Parameters:\n",
    "            - `index`: the index of the image that must be retrieven.\n",
    "            \n",
    "        Returns:\n",
    "            - (`item`, `label`) (`tuple[torch.Tensor, torch.Tensor]`): the item in the ith position in the dataset, along with its label.\n",
    "        \"\"\"\n",
    "\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] Index of the dataloader: {index}\")\n",
    "            print(f\"[DEBUG] Data folder: {self.data_dir[index]}\")\n",
    "            print(f\"[DEBUG] Labels folder: {self.labels_dir[index]}\")\n",
    "\n",
    "        self.data_dir[index] = [self.data_dir[index]] if type(self.data_dir[index]) != list else self.data_dir[index]\n",
    "        self.labels_dir[index] = [self.labels_dir[index]] if type(self.labels_dir[index]) != list else self.labels_dir[index]\n",
    "\n",
    "        return (\n",
    "            [self.__load_video__(data_piece) for data_piece in self.data_dir[index]],\n",
    "            [self.__load_label__(label_piece) for label_piece in self.labels_dir[index]]\n",
    "        )\n",
    "\n",
    "\n",
    "    def __load_video__(self, video_path: str) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Loads a video from the dataset given its path\n",
    "        \n",
    "        Parameters:\n",
    "            - `video_path`: the path of the video that must be loaded\n",
    "            \n",
    "        Returns:\n",
    "            - `video` (`torch.Tensor`): the video as a PyTorch's `Tensor`\n",
    "        \"\"\"\n",
    "        video_path = os.path.join(self.data_path, video_path)\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        if self.debug:\n",
    "            #print(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "            print(f\"[DEBUG] Trying to open the video at path {video_path}\")\n",
    "        to_return = np.ndarray(shape =(75,100,150))\n",
    "\n",
    "        homog, prev_frame = True, None\n",
    "\n",
    "        for i in range(int(cap.get(cv2.CAP_PROP_FRAME_COUNT))):\n",
    "            ret, frame = cap.read()\n",
    "            gframe = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)# .astype('uint8')  # Format to 8-bit image. 'int8' doesn't seem to do the job either\n",
    "\n",
    "            if self.debug:\n",
    "                '''\n",
    "                cv2.imshow(\"Frame\", gframe)\n",
    "                cv2.waitKey(0)\n",
    "                cv2.destroyAllWindows()\n",
    "                cv2.imwrite(\"/workspace/GUNILEO/tests/gframe001.jpg\", gframe)'''\n",
    "                \n",
    "                prev_frame = gframe.shape if prev_frame == None else prev_frame\n",
    "                homog = False if prev_frame != gframe.shape else True\n",
    "                print(gframe.shape, homog)\n",
    "                \n",
    "\n",
    "            facedetect = self.face_detector(gframe)\n",
    "            \n",
    "            #HAVE A CHECK IF THE FACE IS FOUND OR NOT\n",
    "\n",
    "\n",
    "\n",
    "            face_landmarks = self.landmark(gframe, facedetect[0])\n",
    "            xleft = face_landmarks.part(48).x - self.CROPMARGIN\n",
    "            xright = face_landmarks.part(54).x + self.CROPMARGIN\n",
    "            ybottom = face_landmarks.part(57).y + self.CROPMARGIN\n",
    "            ytop = face_landmarks.part(50).y - self.CROPMARGIN\n",
    "\n",
    "            mouth = gframe[ytop:ybottom, xleft:xright]\n",
    "            mouth = cv2.resize(mouth, (150, 100))\n",
    "            \n",
    "            mean = np.mean(mouth)\n",
    "            std_dev = np.std(mouth)\n",
    "            mouth = (mouth - mean) / std_dev\n",
    "            to_return[i] = torch.tensor(mouth)\n",
    "            \n",
    "        cap.release()\n",
    "        return to_return\n",
    "    \n",
    "\n",
    "    def __load_label__(self, label_path: str) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Loads a label from the dataset given its path\n",
    "\n",
    "        Parameters:\n",
    "            - `label_path`: the path of the label that must be loaded;\n",
    "\n",
    "        Returns:\n",
    "            - `label` (`torch.Tensor`): the label as a PyTorch's tensor\n",
    "        \"\"\"\n",
    "        \n",
    "        encoding = [\n",
    "            {\"b\":\"bin\",\"l\":\"lay\",\"p\":\"place\",\"s\":\"set\"},\n",
    "            {\"b\":\"blue\",\"g\":\"green\",\"r\":\"red\",\"w\":\"white\"},\n",
    "            {\"a\":\"at\",\"b\":\"by\",\"i\":\"in\",\"w\":\"with\"},\n",
    "            \"letter\",\n",
    "            {\"z\":\"zero\",\"1\":\"one\",\"2\":\"two\",\"3\":\"three\",\"4\":\"four\",\"5\":\"five\",\"6\":\"six\",\"7\":\"seven\",\"8\":\"eight\",\"9\":\"nine\"},\n",
    "            {\"a\":\"again\",\"n\":\"now\",\"p\":\"please\",\"s\":\"soon\"}\n",
    "            ]\n",
    "        \n",
    "        code = label_path.split(\".\")[0].split(\"_\")[-1]\n",
    "        print(code)\n",
    "        sentence = []\n",
    "        for i, letter in enumerate(code):\n",
    "            corresponding_dict = encoding[i]\n",
    "            next = letter if corresponding_dict == \"letter\" else corresponding_dict[letter]\n",
    "            sentence = sentence + [\" \"] + [x for x in next]\n",
    "        enl = self.encoder.batch_encode(sentence)\n",
    "        if self.debug: print(enl)\n",
    "        return enl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torchinfo\n",
    "\n",
    "class SelectItem(nn.Module):\n",
    "    def __init__(self, item_index):\n",
    "        super(SelectItem, self).__init__()\n",
    "        self._name = 'selectitem'\n",
    "        self.item_index = item_index\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \n",
    "        return inputs[self.item_index]\n",
    "class LabialCNN(nn.Module):\n",
    "    def __init__(self, debug: bool = False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.debug = debug\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv3d(in_channels=1,out_channels=8,kernel_size=(3, 5, 5),padding=(1, 2, 2),stride=(1, 2, 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool3d(kernel_size=(1, 2, 2),stride=(1, 2, 2)),\n",
    "        \n",
    "            nn.Conv3d( in_channels=8,out_channels=16,kernel_size=(3, 5, 5),padding=(1, 2, 2),stride=(1, 1, 1)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool3d(kernel_size=(1, 2, 2),stride=(1, 2, 2)),\n",
    "        \n",
    "            nn.Conv3d( in_channels=16,out_channels=32,kernel_size=(3, 5, 5),padding=(1, 2, 2),stride=(1, 1, 1)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool3d(kernel_size=(1, 2, 2),stride=(1, 2, 2)),\n",
    "             # Left as default, check later if it causes problems\n",
    "            \n",
    "        )    \n",
    "        self.gru = nn.Sequential(\n",
    "            nn.GRU(input_size= 1728,hidden_size= 256,num_layers=2, dropout=0.5 ,bidirectional=True),\n",
    "            SelectItem(0),\n",
    "            \n",
    "            nn.Linear(in_features=512,out_features= 37),\n",
    "            nn.Softmax()\n",
    "        )\n",
    "\n",
    "    # Remember to put FALSE\n",
    "    def forward(self, x):\n",
    "        x = self.cnn(x) # Run through the model\n",
    "        \n",
    "        sh = x.shape\n",
    "        x = torch.reshape(x,(sh[1],sh[0],sh[2],sh[3])) # Reshape so that the channels are flattened, not frames\n",
    "        x = nn.Flatten()(x)\n",
    "        x = self.gru(x)\n",
    "      \n",
    "        \n",
    "        if self.debug: print(f\"Layer's shape: {sh}\")\n",
    "        #x = torch.flatten(x, 1)     # Flatten layer\n",
    "        #if debug: print(f\"  Layer's shape: {x.shape}\")\n",
    "        if self.debug: print(f\"Summary of the layer: a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchmetrics\n",
    "import torch\n",
    "\n",
    "metric = torchmetrics.Accuracy(task=\"multiclass\", num_classes=37)\n",
    "\n",
    "def train_loop(device, dataloader, model, loss_fn, optimizer, epochs, epoch=None, debug=True):\n",
    "    \"\"\"Trains an epoch of the model\n",
    "    \n",
    "    Parameters:\n",
    "        - `device`: destination device\n",
    "        - `dataloader`: the dataloader of the dataset\n",
    "        - `model`: the model used\n",
    "        - `loss_fn`: the loss function of the model\n",
    "        - `optimizer`: the optimizer\n",
    "        - `epoch`: the index of the epoch\n",
    "    \"\"\"\n",
    "    size = len(dataloader)\n",
    "\n",
    "    # Get the batch from the dataset\n",
    "    for batch, (x, y) in enumerate(dataloader):\n",
    "        # Move data to the device used\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        # Compute the prediction and the loss\n",
    "        pred = model(x)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Adjust the weights\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Print some information\n",
    "        if batch % 32 == 0:\n",
    "            loss_value, current_batch = loss.item(), (batch + 1) * len(x)\n",
    "            if debug: print(f\"→ Loss: {loss_value} [Batch {current_batch}/{size}, Epoch {epoch}/{epochs}]\")\n",
    "            accuracy = metric(pred, y)\n",
    "            if debug: print(f\"Accuracy of batch {current_batch}/{size}: {accuracy}\")\n",
    "        \n",
    "    accuracy = metric.compute()\n",
    "    print(f\"=== The epoch {epoch}/{epochs} has finished training ===\")\n",
    "    if debug: print(f\"→ Final accuracy of the epoch: {accuracy}\")\n",
    "    metric.reset()\n",
    "\n",
    "def test_loop(device, dataloader, model, loss_fn, debug=True):\n",
    "    size = len(dataloader)\n",
    "\n",
    "    # Disable the updating of the weights\n",
    "    with torch.no_grad():\n",
    "        for index, (x, y) in enumerate(dataloader):\n",
    "            # Move the data to the device used for testing\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            # Get the model prediction\n",
    "            pred = model(x)\n",
    "\n",
    "            # Get the accuracy score\n",
    "            acc = metric(pred, y)\n",
    "            if debug: print(f\"→ Accuracy for image {index}: {acc}\")\n",
    "    acc = metric.compute()\n",
    "    print(f\"===    The testing loop has finished    ===\")\n",
    "    if debug: print(f\"→ Final testing accuracy of the model: {acc}\")\n",
    "    metric.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataloaders of our project\n",
    "path_data = \"data/matching/fronts\" # \"data/lombardgrid_front/lombardgrid/front\"\n",
    "path_labels = \"data/matching/labels\" # \"data/lombardgrid_alignment/lombardgrid/alignment\"\n",
    "\n",
    "dataset = GNLDataLoader(path_labels, path_data, transform=None, debug=False)\n",
    "\n",
    "# Test\n",
    "print(\n",
    "    f\"[DEBUG] Items in the data folder: {len(sorted(os.listdir(path_data)))}\",\n",
    "    f\"[DEBUG] Items in the labels folder: {len(sorted(os.listdir(path_labels)))}\",\n",
    "    sep=\"\\n\"\n",
    ")\n",
    "\n",
    "dataloader_train = DataLoader(dataset[0:128], batch_size=32, shuffle=True)\n",
    "dataloader_test = DataLoader(dataset[128:192], batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model + Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = LabialCNN(debug=False).to(device)\n",
    "\n",
    "# Print the summary of the model\n",
    "torchinfo.summary(model, (1,75, 100, 150), col_names = (\"input_size\", \"output_size\", \"num_params\", \"kernel_size\", \"mult_adds\"), verbose = 1)\n",
    "\n",
    "epochs = 2\n",
    "batch_size = 50\n",
    "learning_rate = 10 ** (-4)\n",
    "dropout = 0.5\n",
    "\n",
    "loss_fn = nn.CTCLoss(reduction=\"mean\")\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training + Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch_ind in range(epochs):\n",
    "    train_loop(dataloader_train, model, loss_fn, optimizer, epoch_ind, debug=False)\n",
    "    test_loop(dataloader_test, model, loss_fn, debug=False)\n",
    "\n",
    "print(\"=== The training has finished ===\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
