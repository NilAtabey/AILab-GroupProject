{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\Huge G \\cup n \\; \\sqrt{-1} \\; \\ell \\; e \\; \\emptyset\n",
    "$$\n",
    "\n",
    "<p style=\"text-align: center\">A lipsync project, made by Nil Atabey, Leonardo Biason and Günak Yuzak</p>\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=\"center\"><b>Table of Contents</b></h2>\n",
    "\n",
    "1. [Code structure](#1-code-structure)\n",
    "2. [Import of the Packages](#2-import-of-the-packages)\n",
    "3. [Data Loading](#3-data-loading)\n",
    "4. [Model Settings](#4-model-settings)\n",
    "\n",
    "$$\n",
    "\\newcommand{\\goto}{\\; \\longrightarrow \\;}\n",
    "\\newcommand{\\tdconv}{\\text{2D Convolution} }\n",
    "\\newcommand{\\relu}{\\text{ReLU} }\n",
    "$$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Code Structure\n",
    "\n",
    "The code structure is the following:\n",
    "\n",
    "```python\n",
    "project\n",
    " ├ assets\n",
    " │  ├ cnn.py\n",
    " │  └ dataloader.py\n",
    " └ data\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Import of the Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standard packages needed that can be installed with either `conda` or `pip`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch imports\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch import nn\n",
    "import torchmetrics\n",
    "import torchinfo\n",
    "\n",
    "# Utils imports\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom imports from our libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from assets.gnldataloader import GNLDataLoader\n",
    "#from assets.cnn import LabialCNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "\n",
      "None\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m path_labels \u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/lombardgrid_alignment/lombardgrid/alignment\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m dataLoader \u001b[38;5;241m=\u001b[39m GNLDataLoader(path_labels, path_data, transform\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mdataLoader\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m)\n",
      "File \u001b[0;32m/workspaces/GUNILEO/assets/gnldataloader.py:50\u001b[0m, in \u001b[0;36mGNLDataLoader.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Get the ith item(s) in the dataset\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;124;03mParameters:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;124;03mReturns:\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;124;03m    - `item` (`img`): the image in the ith position in the dataset.\"\"\"\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# Get the label + data\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m label_path, data_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabels_dir\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_dir[index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# Apply transformations (if any)\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform:\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "# Create the dataloaders of our project\n",
    "path_data = \"data/lombardgrid_front/lombardgrid/front\"\n",
    "path_labels = \"data/lombardgrid_alignment/lombardgrid/alignment\"\n",
    "\n",
    "dataLoader = GNLDataLoader(path_labels, path_data, transform=None)\n",
    "\n",
    "print(dataLoader[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5319\n",
      "\n",
      "5319\n"
     ]
    }
   ],
   "source": [
    "a, b = sorted(os.listdir(\"data/matching/fronts\")), sorted(os.listdir(\"data/matching/labels\"))\n",
    "\n",
    "print(len(a), len(b), sep=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Model Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following settings are applied:\n",
    "> `device`: specifies where the model must be trained. If an Nvidia GPU is detected, then CUDA will be used;<br>\n",
    "> `epochs`: the number of epochs;<br>\n",
    "> `batch_size`: the size of each singular batch of analysed images;<br>\n",
    "> `learning_rate`: `N/A`;<br>\n",
    "> `loss_fn`: the loss function of the model;<br>\n",
    "> `optimizer`: the optimizer of the model. For now it's `AdamW`, which is more performant than `SGD`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model has the following layers:\n",
    "\n",
    "$$\n",
    "\\underbrace{x}_{\\text{input}} \\goto \\underbrace{st_0(3, \\; 5, \\; 5)}_{\\text{ST CNN}} \\goto \\underbrace{p_0(1, \\; 2, \\; 2)}_{\\text{Normalization Pool}} \\goto \\underbrace{st_1(3, \\; 5, \\; 5)}_{\\text{ST CNN}} \\goto \\underbrace{p_1(1, \\; 2, \\; 2)}_{\\text{Normalization Pool}} \\goto\n",
    "$$\n",
    "$$\n",
    "\\goto \\underbrace{st_2(3, \\; 5, \\; 5)}_{\\text{ST CNN}} \\goto \\underbrace{p_2(1, \\; 2, \\; 2)}_{\\text{Normalization Pool}} \\goto \\underbrace{y}_{\\text{Output}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LabialCNN' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mLabialCNN\u001b[49m(debug\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      5\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m      6\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m16\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'LabialCNN' is not defined"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = LabialCNN(debug=True).to(device)\n",
    "\n",
    "epochs = 2\n",
    "batch_size = 16\n",
    "learning_rate = 0.0001\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
