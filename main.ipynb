{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\Huge G \\cup n \\; \\sqrt{-1} \\; \\ell \\; e \\; \\emptyset\n",
    "$$\n",
    "\n",
    "<p style=\"text-align: center\">A lipsync project, made by Nil Atabey, Leonardo Biason and Günak Yuzak</p>\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=\"center\"><b>Table of Contents</b></h2>\n",
    "\n",
    "1. [Code structure](#1-code-structure)\n",
    "2. [Import of the Packages](#2-import-of-the-packages)\n",
    "3. [Data Loading](#3-data-loading)\n",
    "4. [Model Settings](#4-model-settings)\n",
    "\n",
    "$$\n",
    "\\newcommand{\\goto}{\\; \\longrightarrow \\;}\n",
    "\\newcommand{\\tdconv}{\\text{2D Convolution} }\n",
    "\\newcommand{\\relu}{\\text{ReLU} }\n",
    "$$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Code Structure\n",
    "\n",
    "The code structure is the following:\n",
    "\n",
    "```python\n",
    "project\n",
    " ├ assets\n",
    " │  ├ cnn.py\n",
    " │  └ dataloader.py\n",
    " └ data\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Import of the Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standard packages needed that can be installed with either `conda` or `pip`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch imports\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch import nn\n",
    "import torchmetrics\n",
    "\n",
    "# Utils imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "import cv2\n",
    "import os\n",
    "import dlib\n",
    "import json\n",
    "from torchnlp.encoders import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom imports from our libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from assets.gnldataloader import GNLDataLoader\n",
    "from assets.cnn import LabialCNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62.0\n",
      "tensor([[ 0.8260,  0.7259,  0.5924,  ...,  0.1252,  0.0919,  0.1252],\n",
      "        [ 0.7927,  0.6925,  0.5591,  ...,  0.1252,  0.0585,  0.0919],\n",
      "        [ 0.7927,  0.6925,  0.5591,  ...,  0.1252,  0.0585,  0.0585],\n",
      "        ...,\n",
      "        [ 0.2921,  0.3922,  0.4589,  ...,  0.1252,  0.0585,  0.0585],\n",
      "        [ 0.2921,  0.3255,  0.3588,  ...,  0.0919,  0.0585,  0.0251],\n",
      "        [ 0.2587,  0.2587,  0.2921,  ...,  0.0919,  0.0585, -0.0083]],\n",
      "       dtype=torch.float64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' def test(path):\\n    for file in os.listdir(path):\\n        filename = os.path.join(path,file)\\n        if os.path.isdir(filename):\\n            test(filename)\\n        else:\\n            videoload(filename)\\ntest(\"data/lombardgrid_front\")\\n '"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1 =\"data/lombardgrid_front/lombardgrid/front\"\n",
    "p2 =\"data/lombardgrid_alignment/lombardgrid/alignment\"\n",
    "face_detector = dlib.get_frontal_face_detector()\n",
    "landmark = dlib.shape_predictor(\"shape_predictor_68_face_landmarks_GTX.dat\")\n",
    "alphabet = [x for x in \"abcdefghijklmnopqrstuvwxyz0123456789 \"]\n",
    "encoder = LabelEncoder(alphabet, reserved_labels=['unknown'], unknown_index=0)\n",
    "CROPMARGIN = 20\n",
    "\n",
    "\n",
    "def videoload(path):\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    print(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    for _ in range(int(cap.get(cv2.CAP_PROP_FRAME_COUNT))):\n",
    "        ret,frame = cap.read()\n",
    "        gframe = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        facedetect =face_detector(gframe)\n",
    "        \n",
    "        #HAVE A CHECK IF THE FACE IS FOUND OR NOT\n",
    "\n",
    "        face_landmarks = landmark(gframe, facedetect[0])\n",
    "        xleft = face_landmarks.part(48).x -CROPMARGIN\n",
    "        xright = face_landmarks.part(54).x +CROPMARGIN\n",
    "        ybottom = face_landmarks.part(57).y +CROPMARGIN\n",
    "        ytop = face_landmarks.part(50).y -CROPMARGIN\n",
    "\n",
    "        mouth = gframe[ytop:ybottom,xleft:xright]\n",
    "        mouth = cv2.resize(mouth,(150,100))\n",
    "        \n",
    "        mean = np.mean(mouth)\n",
    "        std_dev = np.std(mouth)\n",
    "        mouth = (mouth - mean) / std_dev\n",
    "        \n",
    "        return torch.tensor(mouth)\n",
    "    cap.release()\n",
    "print(videoload(\"data/lombardgrid_front/lombardgrid/front/s2_p_lbis6s.mov\"))\n",
    "\n",
    "def alignload(path):\n",
    "    encoding =[ {\"b\":\"bin\",\"l\":\"lay\",\"p\":\"place\",\"s\":\"set\"},\n",
    "                {\"b\":\"blue\",\"g\":\"green\",\"r\":\"red\",\"w\":\"white\"},\n",
    "                {\"a\":\"at\",\"b\":\"by\",\"i\":\"in\",\"w\":\"with\"},\n",
    "                \"letter\",\n",
    "                {\"0\":\"zero\",\"1\":\"one\",\"2\":\"two\",\"3\":\"three\",\"4\":\"four\",\"5\":\"five\",\"6\":\"six\",\"7\":\"seven\",\"8\":\"eight\",\"9\":\"nine\"},\n",
    "                {\"a\":\"again\",\"n\":\"now\",\"p\":\"please\",\"s\":\"soon\"}]\n",
    "    code = path.split(\".\")[0].split(\"_\")[-1]\n",
    "    sentence = []\n",
    "    for i, letter in enumerate(code):\n",
    "        corresponding_dict = encoding[i]\n",
    "        next =\"\"\n",
    "        if corresponding_dict == \"letter\":\n",
    "            next = letter\n",
    "        else:next = corresponding_dict[letter]\n",
    "        sentence = sentence + [\" \"] + [x for x in next]\n",
    "  \n",
    "\n",
    "    enl = encoder.batch_encode(sentence)\n",
    "    return enl\n",
    "\n",
    "def loadbothdata(p1,p2):\n",
    "    #MIGHT NEED TO TENSORIZE VIDEO, ALIGN IS ALREADY TENSORIZED\n",
    "    return videoload(p1),alignload(p2)\n",
    "\"\"\" \n",
    "FOR SINGULAR TESTS\n",
    "testvid = \"data/lombardgrid_front/lombardgrid/front/s2_l_bbim3a.mov\"\n",
    "videoload(testvid) \"\"\"\n",
    "\n",
    "#FOR MULTIPLE TESTS\n",
    "\"\"\" def test(path):\n",
    "    for file in os.listdir(path):\n",
    "        filename = os.path.join(path,file)\n",
    "        if os.path.isdir(filename):\n",
    "            test(filename)\n",
    "        else:\n",
    "            videoload(filename)\n",
    "test(\"data/lombardgrid_front\")\n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataloaders of our project\n",
    "# train_data = GNLDataLoader()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Model Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following settings are applied:\n",
    "> `device`: specifies where the model must be trained. If an Nvidia GPU is detected, then CUDA will be used;<br>\n",
    "> `epochs`: the number of epochs;<br>\n",
    "> `batch_size`: the size of each singular batch of analysed images;<br>\n",
    "> `learning_rate`: `N/A`;<br>\n",
    "> `loss_fn`: the loss function of the model;<br>\n",
    "> `optimizer`: the optimizer of the model. For now it's `AdamW`, which is more performant than `SGD`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model has the following layers:\n",
    "\n",
    "$$\n",
    "\\underbrace{x}_{\\text{input}} \\goto \\underbrace{st_0(3, \\; 5, \\; 5)}_{\\text{ST CNN}} \\goto \\underbrace{p_0(1, \\; 2, \\; 2)}_{\\text{Normalization Pool}} \\goto \\underbrace{st_1(3, \\; 5, \\; 5)}_{\\text{ST CNN}} \\goto \\underbrace{p_1(1, \\; 2, \\; 2)}_{\\text{Normalization Pool}} \\goto\n",
    "$$\n",
    "$$\n",
    "\\goto \\underbrace{st_2(3, \\; 5, \\; 5)}_{\\text{ST CNN}} \\goto \\underbrace{p_2(1, \\; 2, \\; 2)}_{\\text{Normalization Pool}} \\goto \\underbrace{y}_{\\text{Output}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = LabialCNN(debug=True).to(device)\n",
    "\n",
    "epochs = 2\n",
    "batch_size = 16\n",
    "learning_rate = 0.0001\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
