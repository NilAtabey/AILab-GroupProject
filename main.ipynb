{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\Huge G \\cup n \\; \\sqrt{-1} \\; \\ell \\; e \\; \\emptyset\n",
    "$$\n",
    "\n",
    "<p style=\"text-align: center\">A lipsync project, made by Nil Atabey, Leonardo Biason and Günak Yuzak</p>\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=\"center\"><b>Table of Contents</b></h2>\n",
    "\n",
    "1. [Code structure](#1-code-structure)\n",
    "2. [Import of the Packages](#2-import-of-the-packages)\n",
    "3. [Data Loading](#3-data-loading)\n",
    "4. [Model Settings](#4-model-settings)\n",
    "\n",
    "$$\n",
    "\\newcommand{\\goto}{\\; \\longrightarrow \\;}\n",
    "\\newcommand{\\tdconv}{\\text{2D Convolution} }\n",
    "\\newcommand{\\relu}{\\text{ReLU} }\n",
    "$$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Code Structure\n",
    "\n",
    "The code structure is the following:\n",
    "\n",
    "```python\n",
    "project\n",
    " ├ assets\n",
    " │  ├ cnn.py\n",
    " │  └ dataloader.py\n",
    " └ data\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Import of the Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standard packages needed that can be installed with either `conda` or `pip`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch imports\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch import nn\n",
    "import torchmetrics\n",
    "import torchinfo\n",
    "\n",
    "# Utils imports\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom imports from our libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from assets.gnldataloader import GNLDataLoader\n",
    "from assets.cnn import LabialCNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to clean the code and make sure that there were the same number of videos and labels, the following code was performed:\n",
    "\n",
    "```python\n",
    "a, b = sorted(os.listdir(\"data/matching/fronts\")), sorted(os.listdir(\"data/matching/labels\"))\n",
    "a_new, b_new = set([item[:-4] for item in a]), set([item[:-5] for item in b])\n",
    "tot = a_new.intersection(b_new)\n",
    "print(tot)\n",
    "\n",
    "for item in b:\n",
    "    if item[:-5] in tot:\n",
    "        prev_path = os.path.join(path_labels, item)\n",
    "        os.rename(prev_path, os.path.join(\"data/matching/labels\", item))\n",
    "\n",
    "print(len(tot))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] The data dir has been recognized\n",
      "[DEBUG] The label dir has been recognized\n",
      "[DEBUG] Items in the data folder: 5319\n",
      "[DEBUG] Items in the labels folder: 5319\n",
      "[DEBUG] Index of the dataloader: slice(1, 3, None)\n",
      "[DEBUG] Data folder: ['s10_l_bbay5n.mov', 's10_l_bbbg8s.mov']\n",
      "[DEBUG] Labels folder: ['s10_l_bbay5n.json', 's10_l_bbbg8s.json']\n",
      "[DEBUG] Trying to open the video at path data/matching/fronts/s10_l_bbay5n.mov\n",
      "[DEBUG] Trying to open the video at path data/matching/fronts/s10_l_bbbg8s.mov\n",
      "tensor([37,  2,  9, 14, 37,  2, 12, 21,  5, 37,  1, 20, 37, 25, 37,  6,  9, 22,\n",
      "         5, 37, 14, 15, 23])\n",
      "tensor([37,  2,  9, 14, 37,  2, 12, 21,  5, 37,  2, 25, 37,  7, 37,  5,  9,  7,\n",
      "         8, 20, 37, 19, 15, 15, 14])\n"
     ]
    }
   ],
   "source": [
    "# Create the dataloaders of our project\n",
    "path_data = \"data/matching/fronts\" # \"data/lombardgrid_front/lombardgrid/front\"\n",
    "path_labels = \"data/matching/labels\" # \"data/lombardgrid_alignment/lombardgrid/alignment\"\n",
    "\n",
    "dataLoader = GNLDataLoader(path_labels, path_data, transform=None, debug=True)\n",
    "\n",
    "# Test\n",
    "print(\n",
    "    f\"[DEBUG] Items in the data folder: {len(sorted(os.listdir(path_data)))}\",\n",
    "    f\"[DEBUG] Items in the labels folder: {len(sorted(os.listdir(path_labels)))}\",\n",
    "    sep=\"\\n\"\n",
    ")\n",
    "\n",
    "part_of_dataset = dataLoader[1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Model Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following settings are applied:\n",
    "> `device`: specifies where the model must be trained. If an Nvidia GPU is detected, then CUDA will be used;<br>\n",
    "> `epochs`: the number of epochs;<br>\n",
    "> `batch_size`: the size of each singular batch of analysed images;<br>\n",
    "> `learning_rate`: `N/A`;<br>\n",
    "> `loss_fn`: the loss function of the model;<br>\n",
    "> `optimizer`: the optimizer of the model. For now it's `AdamW`, which is more performant than `SGD`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model has the following layers:\n",
    "\n",
    "$$\n",
    "\\underbrace{x}_{\\text{input}} \\goto \\underbrace{st_0(3, \\; 5, \\; 5)}_{\\text{ST CNN}} \\goto \\underbrace{p_0(1, \\; 2, \\; 2)}_{\\text{Normalization Pool}} \\goto \\underbrace{st_1(3, \\; 5, \\; 5)}_{\\text{ST CNN}} \\goto \\underbrace{p_1(1, \\; 2, \\; 2)}_{\\text{Normalization Pool}} \\goto\n",
    "$$\n",
    "$$\n",
    "\\goto \\underbrace{st_2(3, \\; 5, \\; 5)}_{\\text{ST CNN}} \\goto \\underbrace{p_2(1, \\; 2, \\; 2)}_{\\text{Normalization Pool}} \\goto \\underbrace{y}_{\\text{Output}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = LabialCNN(debug=True).to(device)\n",
    "\n",
    "epochs = 2\n",
    "batch_size = 50\n",
    "learning_rate = 10 ** (-4)\n",
    "dropout = 0.5\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
