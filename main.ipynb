{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\Huge G \\cup n \\; \\sqrt{-1} \\; \\ell \\; e \\; \\emptyset\n",
    "$$\n",
    "\n",
    "<p style=\"text-align: center\">A lipsync project, made by Nil Atabey, Leonardo Biason and Günak Yuzak</p>\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=\"center\"><b>Table of Contents</b></h2>\n",
    "\n",
    "1. [Code structure](#1-code-structure)\n",
    "2. [Import of the Packages](#2-import-of-the-packages)\n",
    "3. [Data Loading](#3-data-loading)\n",
    "4. [Model Settings](#4-model-settings)\n",
    "5. [Training + Testing](#5-training--testing)\n",
    "\n",
    "$$\n",
    "\\newcommand{\\goto}{\\; \\longrightarrow \\;}\n",
    "\\newcommand{\\tdconv}{\\text{2D Convolution} }\n",
    "\\newcommand{\\relu}{\\text{ReLU} }\n",
    "$$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Code Structure\n",
    "\n",
    "The code structure is the following:\n",
    "\n",
    "```python\n",
    "project\n",
    " ├ assets\n",
    " │  ├ cnn.py\n",
    " │  └ dataloader.py\n",
    " └ data\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Import of the Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standard packages needed that can be installed with either `conda` or `pip`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch imports\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch import nn\n",
    "import torchmetrics\n",
    "import torchinfo\n",
    "\n",
    "# Utils imports\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom imports from our libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from assets.gnldataloader import GNLDataLoader\n",
    "from assets.cnn import LabialCNN\n",
    "from assets.loops import train_loop, test_loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to clean the code and make sure that there were the same number of videos and labels, the following code was performed:\n",
    "\n",
    "```python\n",
    "a, b = sorted(os.listdir(\"data/matching/fronts\")), sorted(os.listdir(\"data/matching/labels\"))\n",
    "a_new, b_new = set([item[:-4] for item in a]), set([item[:-5] for item in b])\n",
    "tot = a_new.intersection(b_new)\n",
    "print(tot)\n",
    "\n",
    "for item in b:\n",
    "    if item[:-5] in tot:\n",
    "        prev_path = os.path.join(path_labels, item)\n",
    "        os.rename(prev_path, os.path.join(\"data/matching/labels\", item))\n",
    "\n",
    "print(len(tot))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Items in the data folder: 5129\n",
      "[DEBUG] Items in the labels folder: 5129\n"
     ]
    }
   ],
   "source": [
    "# Create the dataloaders of our project\n",
    "path_data = \"data/matching/fronts\" # \"data/lombardgrid_front/lombardgrid/front\"\n",
    "path_labels = \"data/matching/labels\" # \"data/lombardgrid_alignment/lombardgrid/alignment\"\n",
    "\n",
    "dataset = GNLDataLoader(path_labels, path_data, transform=None, debug=False)\n",
    "\n",
    "# Test\n",
    "print(\n",
    "    f\"[DEBUG] Items in the data folder: {len(sorted(os.listdir(path_data)))}\",\n",
    "    f\"[DEBUG] Items in the labels folder: {len(sorted(os.listdir(path_labels)))}\",\n",
    "    sep=\"\\n\"\n",
    ")\n",
    "#print(dataset[0][1][0])\n",
    "# print(dataset[0][1][0].shape)\n",
    "\n",
    "dset_train = dataset[0:16]\n",
    "\n",
    "dataloader_train = DataLoader(dset_train, batch_size=8, shuffle=True)\n",
    "dataloader_test = DataLoader(dataset[16:24], batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Labels in datasets are not tensorized, so maybe that's the problem?\n",
    "\n",
    "Normal dataset:\n",
    "- The index determines the piece of data\n",
    "\n",
    "Our dataset:\n",
    "- The index determines the feature $\\Longrightarrow$ MUST BE CONVERTED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([26])\n",
      "torch.Size([23])\n",
      "torch.Size([25])\n",
      "torch.Size([26])\n",
      "torch.Size([25])\n",
      "torch.Size([25])\n",
      "torch.Size([21])\n",
      "torch.Size([24])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "torch.Size([28])\n",
      "torch.Size([25])\n",
      "torch.Size([23])\n",
      "torch.Size([28])\n",
      "torch.Size([29])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"test_data = dataset[1:3]\n",
    "dloader = DataLoader(test_data, batch_size = 1, shuffle = True)\"\"\"\n",
    "\n",
    "for index, (x, y) in enumerate(dset_train):\n",
    "    print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Model Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following settings are applied:\n",
    "> `device`: specifies where the model must be trained. If an Nvidia GPU is detected, then CUDA will be used;<br>\n",
    "> `epochs`: the number of epochs;<br>\n",
    "> `batch_size`: the size of each singular batch of analysed images;<br>\n",
    "> `learning_rate`: `N/A`;<br>\n",
    "> `loss_fn`: the loss function of the model;<br>\n",
    "> `optimizer`: the optimizer of the model. For now it's `AdamW`, which is more performant than `SGD`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model has the following layers:\n",
    "\n",
    "$$\n",
    "\\underbrace{x}_{\\text{input}} \\goto \\underbrace{st_0(3, \\; 5, \\; 5)}_{\\text{ST CNN}} \\goto \\underbrace{p_0(1, \\; 2, \\; 2)}_{\\text{Normalization Pool}} \\goto \\underbrace{st_1(3, \\; 5, \\; 5)}_{\\text{ST CNN}} \\goto \\underbrace{p_1(1, \\; 2, \\; 2)}_{\\text{Normalization Pool}} \\goto\n",
    "$$\n",
    "$$\n",
    "\\goto \\underbrace{st_2(3, \\; 5, \\; 5)}_{\\text{ST CNN}} \\goto \\underbrace{p_2(1, \\; 2, \\; 2)}_{\\text{Normalization Pool}} \\goto \\underbrace{y}_{\\text{Output}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = LabialCNN(debug=False).to(device)\n",
    "\n",
    "# Print the summary of the model\n",
    "torchinfo.summary(model, (1,75, 100, 150), col_names = (\"input_size\", \"output_size\", \"num_params\", \"kernel_size\", \"mult_adds\"), verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 2\n",
    "batch_size = 32\n",
    "learning_rate = 10 ** (-4)\n",
    "dropout = 0.5\n",
    "\n",
    "loss_fn = nn.CTCLoss(reduction=\"mean\")\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5) Training + Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch_ind in range(epochs):\n",
    "    train_loop(device,dataloader_train, model, loss_fn, optimizer,epochs, epoch_ind, debug=False)\n",
    "    test_loop(device,dataloader_test, model, loss_fn, debug=False)\n",
    "\n",
    "print(\"=== The training has finished ===\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
