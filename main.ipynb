{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\Huge G \\cup n \\; \\sqrt{-1} \\; \\ell \\; e \\; \\emptyset\n",
    "$$\n",
    "\n",
    "<p style=\"text-align: center\">A lipsync project, made by Nil Atabey, Leonardo Biason and Günak Yuzak</p>\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=\"center\"><b>Table of Contents</b></h2>\n",
    "\n",
    "1. [Code structure](#1-code-structure)\n",
    "2. [Import of the Packages](#2-import-of-the-packages)\n",
    "3. [Data Loading](#3-data-loading)\n",
    "4. [Model Settings](#4-model-settings)\n",
    "\n",
    "$$\n",
    "\\newcommand{\\goto}{\\; \\longrightarrow \\;}\n",
    "\\newcommand{\\tdconv}{\\text{2D Convolution} }\n",
    "\\newcommand{\\relu}{\\text{ReLU} }\n",
    "$$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Code Structure\n",
    "\n",
    "The code structure is the following:\n",
    "\n",
    "```python\n",
    "project\n",
    " ├ assets\n",
    " │  ├ cnn.py\n",
    " │  └ dataloader.py\n",
    " └ data\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Import of the Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standard packages needed that can be installed with either `conda` or `pip`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch imports\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch import nn\n",
    "import torchmetrics\n",
    "import torchinfo\n",
    "\n",
    "# Utils imports\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom imports from our libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from assets.gnldataloader import GNLDataLoader\n",
    "#from assets.cnn import LabialCNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to clean the code and make sure that there were the same number of videos and labels, the following code was performed:\n",
    "\n",
    "```python\n",
    "a, b = sorted(os.listdir(\"data/matching/fronts\")), sorted(os.listdir(path_labels))\n",
    "a_new, b_new = set([item[:-4] for item in a]), set([item[:-5] for item in b])\n",
    "tot = a_new.intersection(b_new)\n",
    "print(tot)\n",
    "\n",
    "for item in b:\n",
    "    if item[:-5] in tot:\n",
    "        prev_path = os.path.join(path_labels, item)\n",
    "        os.rename(prev_path, os.path.join(\"data/matching/labels\", item))\n",
    "\n",
    "print(len(tot))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([], dtype=float64), tensor([37,  2,  9, 14, 37,  2, 12, 21,  5, 37,  9, 14, 37,  1, 37, 15, 14,  5,\n",
      "        37, 19, 15, 15, 14]))\n"
     ]
    }
   ],
   "source": [
    "# Create the dataloaders of our project\n",
    "path_data = \"data/lombardgrid_front/lombardgrid/front\"\n",
    "path_labels = \"data/lombardgrid_alignment/lombardgrid/alignment\"\n",
    "\n",
    "dataLoader = GNLDataLoader(path_labels, path_data, transform=None, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5319\n",
      "\n",
      "5319\n"
     ]
    }
   ],
   "source": [
    "a, b = sorted(os.listdir(\"data/matching/fronts\")), sorted(os.listdir(\"data/matching/labels\"))\n",
    "\n",
    "print(len(a), len(b), sep=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Model Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following settings are applied:\n",
    "> `device`: specifies where the model must be trained. If an Nvidia GPU is detected, then CUDA will be used;<br>\n",
    "> `epochs`: the number of epochs;<br>\n",
    "> `batch_size`: the size of each singular batch of analysed images;<br>\n",
    "> `learning_rate`: `N/A`;<br>\n",
    "> `loss_fn`: the loss function of the model;<br>\n",
    "> `optimizer`: the optimizer of the model. For now it's `AdamW`, which is more performant than `SGD`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model has the following layers:\n",
    "\n",
    "$$\n",
    "\\underbrace{x}_{\\text{input}} \\goto \\underbrace{st_0(3, \\; 5, \\; 5)}_{\\text{ST CNN}} \\goto \\underbrace{p_0(1, \\; 2, \\; 2)}_{\\text{Normalization Pool}} \\goto \\underbrace{st_1(3, \\; 5, \\; 5)}_{\\text{ST CNN}} \\goto \\underbrace{p_1(1, \\; 2, \\; 2)}_{\\text{Normalization Pool}} \\goto\n",
    "$$\n",
    "$$\n",
    "\\goto \\underbrace{st_2(3, \\; 5, \\; 5)}_{\\text{ST CNN}} \\goto \\underbrace{p_2(1, \\; 2, \\; 2)}_{\\text{Normalization Pool}} \\goto \\underbrace{y}_{\\text{Output}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LabialCNN' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mLabialCNN\u001b[49m(debug\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      5\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m      6\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m16\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'LabialCNN' is not defined"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = LabialCNN(debug=True).to(device)\n",
    "\n",
    "epochs = 2\n",
    "batch_size = 16\n",
    "learning_rate = 0.0001\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
